<!doctype html>
<html lang="en">

<head>
    <title>Zhao Zhang</title>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="./css/bootstrap.min.css">
    <style>
        .vspace-top-left {
            margin-top: 25px;
            margin-left: 25px;
        }

        .vspace-top {
            margin-top: 30px;
        }
        .vspace-minitop {
            margin-top: 20px;
        }

        .paper-title {
            margin-top: 8px;
            font-weight: bold;
            color: gray
        }

        .paper-authors {
            font-style: italic;

        }

        .paper-pub {
            font-weight: bold;
            color: gray;
            font-style: italic
        }
    </style>
</head>

<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
        <div class="container">
            <a class="navbar-brand" href="index.html">Home</a>
            <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive"
             aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item">
                        <a class="nav-link active" href="./publications.html">Publications
                            <span class="sr-only">(current)</span>
                        </a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="./data.html">Codes/Datasets
                            <span class="sr-only">(current)</span>
                        </a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#">Useful links
                            <span class="sr-only">(current)</span>
                        </a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>


    <section class="container">
        <!-- Page Heading/Breadcrumbs -->
        <h1 class="mt-4 mb-3">Zhao Zhang
            <small>'s Publications</small>
        </h1>

        <ol class="breadcrumb">
            <li class="breadcrumb-item">
                <a href="index.html">Home</a>
            </li>
            <li class="breadcrumb-item active">Publications</li>
        </ol>

        <div class="row vspace-top">
            <div class="col-md-12">
                <h2>
                    Preprint Papers
                </h2>
                <!-- 25 Layton -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Layton: Latent Consistency Tokenizer for 1024-pixel Image Reconstruction and Generation by 256 Tokens
                                </span>
                                <br />
                                <span class="paper-authors">
                                    Qingsong Xie, <strong class="text-info">Zhao Zhang</strong>, Zhe Huang, Yanhao Zhang, Haonan Lu, Zhenyu Yang
                                </span>
                                <br />
                                <span class="paper-pub">ArXiv</span>  &nbsp
                                <a href="https://arxiv.org/pdf/2503.08377" target="_black">[PDF]</a>
                                <a href="https://github.com/OPPO-Mente-Lab/Layton">[Project]</a>
                                <a href="./papers/25_layton/bibtex.txt" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/25_layton/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>
                <!-- 23 Shikra -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Shikra: Unleashing Multimodal LLM’s Referential Dialogue Magic
                                </span>
                                <br />
                                <span class="paper-authors">
                                    Keqin Chen, <strong class="text-info">Zhao Zhang*</strong>, Weili Zeng, Richong Zhang, Feng Zhu, Rui Zhao
                                </span>
                                <br />
                                <span class="paper-pub">arXiv</span>  &nbsp
                                <a href="https://arxiv.org/abs/2306.15195" target="_black">[PDF]</a>
                                <a href="https://github.com/shikras/shikra"_black">[Code]</a>
                                <a href="./papers/23_shikra/bibtex.txt" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/23_shikra/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>
                <br/>

                <!-- 22 IHRR -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Image Harmonization by Matching Regional References</span>
                                <br />
                                <span class="paper-authors">
                                    Ziyue Zhu, <strong class="text-info">Zhao Zhang</strong>, Zheng Lin, Ruiqi Wu, Chunle Guo
                                </span>
                                <br />
                                <span class="paper-pub">arXiv</span>  &nbsp
                                <a href="https://arxiv.org/abs/2204.04715" target="_black">[PDF]</a>
                                <a href="#"_black">[Code]</a>
                                <a href="#" target="_black">[中译版]</a>
                                <a href="./papers/22_IHRR/bibtex.txt" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/22_IHRR/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>


                <hr />                

                <h2>
                    Journal Papers
                </h2>
                <h4 class="vspace-minitop">
                    2025
                </h4>
                <!-- 25 RelationLLM -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">RelationLMM: Large Multimodal Model as Open and Versatile Visual Relationship Generalist
                                </span>
                                <br />
                                <span class="paper-authors">
                                    Chi Xie, Shuang Liang, Jie Li, <strong class="text-info">Zhao Zhang</strong>, Feng Zhu, Rui Zhao
                                </span>
                                <br />
                                <span class="paper-pub">TPAMI 2025</span>  &nbsp
                                <a href="https://ieeexplore.ieee.org/abstract/document/10845195" target="_black">[Paper]</a>
                                <a href="./papers/25_relationlmm/bibtex.txt" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/25_relationlmm/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>
                <!-- 25 IST -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">User-Oriented Interactive Style Transfer</span>
                                <br />
                                <span class="paper-authors">
                                    Zheng Lin, <strong class="text-info">Zhao Zhang</strong>, Kang-Rui Zhang, Bo Ren, Ming-Ming Cheng
                                </span>
                                <br />
                                <span class="paper-pub">CVMJ 2025</span>  &nbsp
                                <a href="https://arxiv.org/abs/2203.13470" target="_black">[PDF]</a>
                                <a href="#"_black">[Code]</a>
                                <a href="#" target="_black">[中译版]</a>
                                <a href="./papers/22_IST/bibtex.txt" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/22_IST/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>

                <h4 class="vspace-minitop">
                    2023
                </h4>
                
                <!-- 23 PAMI -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Co-Salient Object Detection with Co-Representation Purification</span>
                                <br />
                                <span class="paper-authors">
                                    Ziyue Zhu*, <strong class="text-info">Zhao Zhang*</strong>, Zheng Lin, Xing Sun, Ming-Ming Cheng
                                </span>
                                <br />
                                <span class="paper-pub">TPAMI 2023 </span>  &nbsp
                                    <a href="#" target="https://ieeexplore.ieee.org/document/10008072">[PDF]</a>
                                    <a href="#"_black">[Code]</a>
                                    <a href="#" target="_black">[中译版]</a>
                                    <a href="./papers/23_CoRP/bibtex.txt" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/23_CoRP/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>

                <h4 class="vspace-minitop">
                    2022
                </h4>

                <!-- 22 CVMJ SeqCut -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Sequential Interactive Image Segmentation</span>
                                <br />
                                <span class="paper-authors">
                                    Zheng Lin, <strong class="text-info">Zhao Zhang</strong>, Zi-Yue Zhu, Deng-Ping Fan, Xia-Lei Liu
                                </span>
                                <br />
                                <span class="paper-pub">CVMJ 2022 </span>  &nbsp
                                    <a href="#" target="_black">[PDF]</a>
                                    <a href="#"_black">[Code]</a>
                                    <a href="#" target="_black">[中译版]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/22_SeqCut/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>

                <h4 class="vspace-minitop">
                    2021
                </h4>

                <!-- 21 TIP BiANet -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Bilateral Attention Network for RGB-D Salient Object Detection</span>
                                <br />
                                <span class="paper-authors">
                                    <strong class="text-info">Zhao Zhang</strong>, Zheng Lin, Jun Xu, Wenda Jin, Shao-Ping Lu, and Deng-Ping Fan
                                </span>
                                <br />
                                <span class="paper-pub">TIP 2021</span>  &nbsp
                                <a href="https://ieeexplore.ieee.org/document/9321705" target="_black">[PDF]</a>
                                <a href="https://github.com/zzhanghub/bianet" target="_black">[Code]</a>
                                <a href="./papers/20_BiANet/bibtex.txt" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/20_BiANet/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>


                <h4 class="vspace-minitop">
                    2020
                </h4>

                <!-- 20 TNNLS D3Net -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Rethinking RGB-D Salient Object Detection: Models, Datasets, and Large-Scale Benchmarks</span>
                                <br />
                                <span class="paper-authors">
                                    Deng-Ping Fan, Zheng Lin, <strong class="text-info">Zhao Zhang</strong>, Menglong Zhu, Ming-Ming Cheng
                                </span>
                                <br />
                                <span class="paper-pub">TNNLS 2020</span>  &nbsp
                                <a href="https://ieeexplore.ieee.org/document/9107477" target="_black">[PDF]</a>
                                <a href="https://github.com/DengPingFan/D3NetBenchmark" target="_black">[Code]</a>
                                <a href="http://dpfan.net/d3netbenchmark/" target="_black">[Project]</a>
                                <a href="#" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/20_D3Net/keyimg.png" class="img-responsive img-thumbnail" height="90" width="200"/>
                    </div>
                </div>


                <hr />

                <!-- 会议论文 -->
                <h2 class="vspace-top">
                    Conference Papers
                </h2>
                <h4 class="vspace-minitop">
                    2025
                </h4>
                <!-- 25 DeAM -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Decomposition of Graphic Design with Unified Multimodal Model
                                </span>
                                <br />
                                <span class="paper-authors">
                                    Hui Nie, <strong class="text-info">Zhao Zhang</strong>, Yutao Cheng, Maoke Yang, Gonglei Shi, Qingsong Xie, Jie Shao, Xinglong Wu
                                </span>
                                <br />
                                <span class="paper-pub">ICML 2025</span>  &nbsp
                                <a href="#" target="_black">[Repo Coming Soon]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/25_deam/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>
                <!-- 24 Graphist -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Graphic Design with Large Multimodal Model
                                </span>
                                <br />
                                <span class="paper-authors">
                                    Yutao Cheng*, <strong class="text-info">Zhao Zhang*</strong>, Maoke Yang*, Hui Nie, Chunyuan Li, Xinglong Wu, Jie Shao
                                </span>
                                <br />
                                <span class="paper-pub">AAAI 2025</span>  &nbsp
                                <a href="https://arxiv.org/abs/2404.14368" target="_black">[PDF]</a>
                                <a href="https://github.com/graphic-design-ai/graphist">[Project]</a>
                                <a href="./papers/24_graphist/bibtex.txt" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/24_graphist/keyimg.jpg" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>
                <h4 class="vspace-minitop">
                    2024
                </h4>

                <!-- 24 ISEKAI -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Link-Context Learning for Multimodal LLMs
                                </span>
                                <br />
                                <span class="paper-authors">
                                    Yan Tai, Weichen Fan, <strong class="text-info">Zhao Zhang</strong>, Feng Zhu, Rui Zhao, Ziwei Liu
                                </span>
                                <br />
                                <span class="paper-pub">CVPR 2024</span>  &nbsp
                                <a href="https://arxiv.org/abs/2308.07891" target="_black">[PDF]</a>
                                <a href="https://github.com/isekai-portal/Link-Context-Learning"_black">[Code]</a>
                                <a href="./papers/23_isekai/" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/23_isekai/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>
                <br/> 

                <h4 class="vspace-minitop">
                    2023
                </h4>

                <!-- 23 D-Cube -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Described Object Detection: Liberating Object Detection with Flexible Expressions
                                </span>
                                <br />
                                <span class="paper-authors">
                                    Chi Xie*, <strong class="text-info">Zhao Zhang*</strong>, Yixuan Wu, Feng Zhu, Rui Zhao, Shuang Liang
                                </span>
                                <br />
                                <span class="paper-pub">NeurlPS 2023</span>  &nbsp
                                <a href="https://arxiv.org/abs/2307.12813" target="_black">[PDF]</a>
                                <a href="https://github.com/shikras/d-cube"_black">[Code]</a>
                                <a href="papers/23_dcube/bibtex.txt" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/23_dcube/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>

                <!-- 23 GRES -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Advancing Referring Expression Segmentation Beyond Single Image
                                </span>
                                <br />
                                <span class="paper-authors">
                                    Yixuan Wu*, <strong class="text-info">Zhao Zhang*</strong>, Chi Xie, Feng Zhu, Rui Zhao
                                </span>
                                <br />
                                <span class="paper-pub">ICCV 2023</span>  &nbsp
                                <a href="https://arxiv.org/abs/2305.12452" target="_black">[PDF]</a>
                                <a href="https://github.com/yixuan730/group-res"_black">[Code]</a>
                                <a href="papers/23_GRES/bibtex.txt" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/23_GRES/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>

                <h4 class="vspace-minitop">
                    2022
                </h4>


                <!-- 22 ECCV PAC-Net -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">PAC-Net: Highlight Your Video via History Preference Modeling</span>
                                <br />
                                <span class="paper-authors">
                                    Hang Wang, Penghao Zhou, Chong Zhou, <strong class="text-info">Zhao Zhang</strong>, Xing Sun
                                </span>
                                <br />
                                <span class="paper-pub">ECCV 2022 </span>  &nbsp
                                <a href="#" target="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136940602.pdf">[PDF]</a>
                                <a href="./papers/22_FocusCut/bibtex.txt" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/22_PACNet/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>
    
                <!-- 22 ACM MM MMIIS -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Multi-Mode Interactive Image Segmentation</span>
                                <br />
                                <span class="paper-authors">
                                    Zheng Lin, <strong class="text-info">Zhao Zhang</strong>*, Ling-Hao Han, Shao-Ping Lu
                                </span>
                                <br />
                                <span class="paper-pub">ACM MM 2022 </span>  &nbsp
                                    <a href="#" target="_black">[PDF]</a>
                                    <a href="#"_black">[Code]</a>
                                    <a href="#" target="_black">[中译版]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/22_MMIIS/keyimg.png" class="img-responsive" height="120" width="200"/>
                    </div>
                </div>
                <!-- 22 ACM MM KnifeCut -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">KnifeCut: Refining Thin Part Segmentation with Cutting Lines</span>
                                <br />
                                <span class="paper-authors">
                                    Zheng Lin, Zheng-Peng Duan, <strong class="text-info">Zhao Zhang</strong>, Chunle Guo, Ming-Ming Cheng
                                </span>
                                <br />
                                <span class="paper-pub">ACM MM 2022  (<b style="color:#ec4d4dc4";>Oral</b>) </span>  &nbsp
                                    <a href="#" target="_black">[PDF]</a>
                                    <a href="#"_black">[Code]</a>
                                    <a href="#" target="_black">[中译版]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/22_KnifeCut/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>               
                <!-- 22 CVPR FocusCut -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">FocusCut: Diving into a Focus View in Interactive Segmentation</span>
                                <br />
                                <span class="paper-authors">
                                    Zheng Lin, Zheng-Peng Duan, <strong class="text-info">Zhao Zhang</strong>, Chun-Le Guo, Ming-Ming Cheng
                                </span>
                                <br />
                                <span class="paper-pub">CVPR 2022 (<b style="color:#ec4d4dc4";>Oral</b>)</span>  &nbsp
                                <a href="#" target="_black">[PDF]</a>
                                <a href="# target="_black">[Code]</a>
                                <a href="#" target="_black">[中译版]</a>
                                <a href="./papers/22_FocusCut/bibtex.txt" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/22_FocusCut/keyimg.jpg" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div> 
                <h4 class="vspace-minitop">
                    2020
                </h4>
                <!-- 20 ECCV GICD -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Gradient-Induced Co-Saliency Detection</span>
                                <br />
                                <span class="paper-authors">
                                    <strong class="text-info">Zhao Zhang*</strong>, Wenda Jin*, Jun Xu, Ming-Ming Cheng
                                </span>
                                <br />
                                <span class="paper-pub">ECCV 2020</span>  &nbsp
                                <a href="https://arxiv.org/abs/2004.13364" target="_black">[PDF]</a>
                                <a href="./coca.html" target="_black">[Project]</a>
                                <a href="https://github.com/zzhanghub/gicd" target="_black">[Code]</a>
                                <a href="https://www.bilibili.com/video/BV1y5411a7Rq/" target="_black">[Short Video]</a>
                                <a href="https://www.bilibili.com/video/BV1bi4y137c6" target="_black">[Long Video]</a>
                                <a href="./papers/20_GICD/slides.pdf" target="_black">[Slides]</a>
                                <!-- <a href="./papers/20_GICD/translation.pdf" target="_black">[中译版]</a> -->
                                <a href="#" target="_black">[中译版]</a>
                                <a href="./papers/20_GICD/bibtex.txt" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/20_GICD/keyimg.png" class="img-responsive img-thumbnail" height="60" width="200"/>
                    </div>
                </div>



                <!-- 20 CVPR FCA-Net -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Interactive Image Segmentation with First Click Attention</span>
                                <br />
                                <span class="paper-authors">
                                    Zheng Lin, <strong class="text-info">Zhao Zhang</strong>, Lin-Zhuo Chen, Ming-Ming Cheng, Shao-Ping Lu
                                </span>
                                <br />
                                <span class="paper-pub">CVPR 2020</span>  &nbsp
                                <a href="http://openaccess.thecvf.com/content_CVPR_2020/html/Lin_Interactive_Image_Segmentation_With_First_Click_Attention_CVPR_2020_paper.html" target="_black">[PDF]</a>
                                <a href="https://github.com/frazerlin/fcanet" target="_black">[Code]</a>
                                <a href="https://mmcheng.net/fclick/" target="_black">[Project]</a>
                                <a href="#" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/20_FCANet/keyimg.png" class="img-responsive img-thumbnail" height="90" width="200"/>
                    </div>
                </div>

                <h4 class="vspace-minitop">
                    2018
                </h4>
                <!-- 18 ICASSP SRDCCA -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Low Resolution Face Recognition and Reconstruction via Deep Canonical
                            Correlation Analysis</span>
                                <br />
                                <span class="paper-authors">
                                    <strong class="text-info">Zhao Zhang</strong> Yun-Hao Yuan, Xiao-bo Shen, Yun Li
                                </span>
                                <br />
                                <span class="paper-pub">ICASSP 2018</span>  &nbsp
                                <a href="https://ieeexplore.ieee.org/abstract/document/8461985/" target="_black">[PDF]</a>
                                <a href="#" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/18_SRDCCA/keyimg.png" class="img-responsive img-thumbnail" height="90" width="200"/>
                    </div>
                </div>

                <h4 class="vspace-minitop">
                    2017
                </h4>
                <!-- 17 ICONIP SRKCCA -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Face Hallucination and Recognition Using Kernel Canonical Correlation
                                    Analysis</span>
                                <br />
                                <span class="paper-authors">
                                    <strong class="text-info">Zhao Zhang</strong> Yun-Hao Yuan, Yun Li, Bin Li, Ji-Peng Qiang
                                </span>
                                <br />
                                <span class="paper-pub">ICONIP 2017 (<b style="color:#ec4d4dc4";>Oral</b>)</span>  &nbsp
                                <a href="https://link.springer.com/chapter/10.1007/978-3-319-70136-3_67" target="_black">[PDF]</a>
                                <a href="#" target="_black">[Slides]</a>
                                <a href="#" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                    <div class="col-md-3">
                        <img src="./papers/17_SRKCCA/keyimg.png" class="img-responsive img-thumbnail" height="90" width="200"/>
                    </div>
                </div>

                <!-- 17 ICONIP SDCCA -->
                <div class="row vspace-top-lite">
                    <div class="col-md-9">
                        <ul>
                            <p>
                                <span class="paper-title">Supervised Deep Canonical Correlation Analysis for Multiview Feature
                                    Learning</span>
                                <br />
                                <span class="paper-authors">
                                    Yan Liu, Yun Li, Yun-Hao Yuan, Ji-Peng Qiang, Min Ruan,
                                    <strong class="text-info">Zhao Zhang</strong>
                                </span>
                                <br />
                                <span class="paper-pub">ICONIP 2017</span>  &nbsp
                                <a href="https://link.springer.com/chapter/10.1007/978-3-319-70136-3_61" target="_black">[PDF]</a>
                                <a href="#" target="_black">[bib]</a>
                            </p>
                        </ul>
                    </div>
                </div>

            </div>

        </div>
    </section>




    <footer class="py-3 bg-dark vspace-top">
        <div class="container">
            <p class="m-0 text-center text-white">Copyright &copy; Your Website 2018</p>
        </div>
    </footer>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
</body>

</html>